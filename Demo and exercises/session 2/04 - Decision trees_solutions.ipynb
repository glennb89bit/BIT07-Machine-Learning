{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug dataset\n",
    "Imagine that you are a medical researcher compiling data for a study. You have collected data about a set of patients, all of whom suffered from the same illness. During their course of treatment, each patient responded to one of 5 medications, Drug A, Drug B, Drug c, Drug x and y.\n",
    "\n",
    "Part of your job is to build a model to find out which drug might be appropriate for a future patient with the same illness. The features of this dataset are Age, Sex, Blood Pressure, and the Cholesterol of the patients, and the target is the drug that each patient responded to.\n",
    "\n",
    "It is a sample of multiclass classifier, and you can use the training part of the dataset to build a decision tree, and then use it to predict the class of a unknown patient, or to prescribe a drug to a new patient.\n",
    "\n",
    "https://www.kaggle.com/pablomgomez21/drugs-a-b-c-x-y-for-decision-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  drugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  drugY"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv(\"data/drugs.csv\")\n",
    "# Show the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the total amount of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Drug', ylabel='count'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the distribution of the target column\n",
    "sns.countplot(x='Drug',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X=df.drop(\"Drug\",axis=1)\n",
    "y=df.Drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  BP  Cholesterol  Na_to_K\n",
       "0     23    0   0            0   25.355\n",
       "1     47    1   1            0   13.093\n",
       "2     47    1   1            0   10.114\n",
       "3     28    0   2            0    7.798\n",
       "4     61    0   1            0   18.043\n",
       "..   ...  ...  ..          ...      ...\n",
       "195   56    0   1            0   11.567\n",
       "196   16    1   1            0   12.006\n",
       "197   52    1   2            0    9.894\n",
       "198   23    1   2            1   14.020\n",
       "199   40    0   1            1   11.349\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find a way to change the categorical (text) features into numeric features.\n",
    "# Different options are available. The best one being LabelEncoder():\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "# \n",
    "# Other options are one-hot encoding and pd.get_dummies functions\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "\n",
    "le = LabelEncoder()\n",
    "X.Sex = le.fit_transform(X.Sex)\n",
    "X.BP = le.fit_transform(X.BP)\n",
    "X.Cholesterol = le.fit_transform(X.Cholesterol)\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into a training and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random forest classifier model. Set max_depth parameter to 2\n",
    "# You also might wanna play with the class_weight parameter\n",
    "model = RandomForestClassifier(max_depth=2,class_weight=\"balanced\")\n",
    "# Fit the model\n",
    "model.fit(X_train,y_train)\n",
    "# Print the score on the test set\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  0  0  0  0]\n",
      " [ 1  2  0  0  0]\n",
      " [ 0  0  4  0  0]\n",
      " [ 0  0  3  7  0]\n",
      " [ 0  0  0  0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.83      1.00      0.91         5\n",
      "       drugB       1.00      0.67      0.80         3\n",
      "       drugC       0.57      1.00      0.73         4\n",
      "       drugX       1.00      0.70      0.82        10\n",
      "       drugY       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           0.90        40\n",
      "   macro avg       0.88      0.87      0.85        40\n",
      "weighted avg       0.94      0.90      0.90        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict values for the test set\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "# Print a confusion matrix and classification report\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimizations\n",
    "Use a grid, random or bayes search to do some hyperparameter optimizations.\n",
    "\n",
    "For possible hyperparameters to tune, take a look at the documentation of random forest trees:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Keep max_depth at 1 and/or 2, as otherwise, your tree would get everything right in the training set.\n",
    "\n",
    "Note there is not really a right answer. It's just about trying different things and seeing if you can implement a search yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:   36.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'class_weight': ['balanced', 'balanced_subsample',\n",
       "                                           None],\n",
       "                          'criterion': ['gini', 'entropy'], 'max_depth': [1, 2],\n",
       "                          'max_features': ['sqrt', 'log2', None],\n",
       "                          'max_samples': [0.5, 0.7, 0.9],\n",
       "                          'n_estimators': [50, 100, 150]}],\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizations\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "baseModel=RandomForestClassifier()\n",
    "parameters=[{\n",
    "                \"n_estimators\":[50,100,150],\n",
    "                \"criterion\":[\"gini\",\"entropy\"],\n",
    "                \"max_depth\":[1,2],\n",
    "                \"max_features\":[\"sqrt\",\"log2\",None],\n",
    "                \"class_weight\":[\"balanced\",\"balanced_subsample\",None],\n",
    "                \"max_samples\":[0.5,0.7,0.9]\n",
    "            }]\n",
    "\n",
    "gsearch = GridSearchCV(estimator=baseModel,param_grid=parameters,cv=5,n_jobs=-1,verbose=5)\n",
    "\n",
    "gsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'max_samples': 0.5, 'n_estimators': 50}\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=2, max_features='sqrt', max_samples=0.5,\n",
      "                       n_estimators=50)\n"
     ]
    }
   ],
   "source": [
    "# Print the score of the best model of your search\n",
    "print(gsearch.score(X_test,y_test))\n",
    "\n",
    "# Print the parameters that give you the best model\n",
    "print(gsearch.best_params_)\n",
    "print(gsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "Try now to also create a boosted model for the random forest trees and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.83      1.00      0.91         5\n",
      "       drugB       1.00      0.67      0.80         3\n",
      "       drugC       1.00      1.00      1.00         4\n",
      "       drugX       1.00      1.00      1.00        10\n",
      "       drugY       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.97      0.93      0.94        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "[[ 5  0  0  0  0]\n",
      " [ 1  2  0  0  0]\n",
      " [ 0  0  4  0  0]\n",
      " [ 0  0  0 10  0]\n",
      " [ 0  0  0  0 18]]\n",
      "97.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Gradient boosting\n",
    "clf_gradientboost = GradientBoostingClassifier(n_estimators=100,learning_rate=0.8,max_depth=1)\n",
    "\n",
    "clf_gradientboost.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = clf_gradientboost.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(accuracy_score(y_test, y_pred) * 100) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8(<python environment>)",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
